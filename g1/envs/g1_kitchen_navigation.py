
# g1_kitchen_navigation.py
import os
import numpy as np
from isaacgym import gymapi, gymtorch
# from isaacgym.torch_utils import quat_rotate_inverse, quat_apply, to_torch
from isaacgym.torch_utils import quat_rotate_inverse, quat_apply, to_torch, get_axis_params  # æ·»åŠ get_axis_params
from isaacgym.torch_utils import torch_rand_float


import torch

# ä»è¯¾ç¨‹åŸºç¡€ç±»ç»§æ‰¿
from g1.envs.curriculum.curriculum_base import G1CurriculumBase
# å¯¼å…¥ kitchen è§£æå·¥å…·
try:
    from g1.utils.kitchen_utils import parse_lisdf # ç¡®ä¿è·¯å¾„æ­£ç¡®
except ImportError:
    print("âŒ é”™è¯¯: æ— æ³•å¯¼å…¥ kitchen_utils. è¯·ç¡®ä¿ g1/utils/kitchen_utils.py æ–‡ä»¶å­˜åœ¨ã€‚")
    raise

# å¯¼å…¥åŸºç¡€æœºå™¨äººé…ç½®ç±» (å¯é€‰)
from g1.envs.base.legged_robot_config import LeggedRobotCfg

# å®šä¹‰é¡¹ç›®æ ¹ç›®å½• (å¦‚æœéœ€è¦åŠ è½½èµ„æº)
try:
    G1_ROOT_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
except NameError:
    G1_ROOT_DIR = "" # Fallback

class G1KitchenNavigation(G1CurriculumBase):
    """ç¬¬äºŒé˜¶æ®µï¼šå¨æˆ¿ç¯å¢ƒå¯¼èˆªé¿éšœè®­ç»ƒ.
    ç»§æ‰¿è‡ª G1CurriculumBaseï¼ŒåŠ è½½å¨æˆ¿ç¯å¢ƒï¼Œå¤„ç†å¤š Actor çŠ¶æ€ï¼Œ
    å¹¶å®ç°å¯¼èˆªå’Œé¿éšœé€»è¾‘ã€‚
    """

    # !!! ä¿®æ”¹æ„é€ å‡½æ•°ç­¾åä»¥åŒ¹é… BaseTask !!!
    def __init__(self, cfg, sim_params, physics_engine, sim_device, headless, gym_handle=None, sim_handle=None):
        print("--- Initializing G1KitchenNavigation (Stage 2) ---")


        # --- è®°å½•ä¼ å…¥çš„gymå’Œsimå¥æŸ„ ---
        self.external_gym_handle = gym_handle
        self.external_sim_handle = sim_handle

        # --- Kitchen Assets and Actors (åˆå§‹åŒ–ä¸ºç©º) ---
        self.kitchen_assets = {}
        self.kitchen_poses = {}
        self.kitchen_scales = {}
        self.kitchen_actors_by_env = []
        self.num_kitchen_bodies = 0
        self.num_kitchen_dofs = 0

        # --- é‡è¦ï¼šæ·»åŠ è°ƒè¯•æ ‡è®° ---
        self.create_sim_called = False
        self.create_envs_called = False

        # --- Navigation State (åˆå§‹åŒ–ä¸ºç©º) ---
        self.waypoints = {}
        self.waypoint_names = []
        self.waypoint_positions = None
        self.active_waypoint_indices = []
        self.current_waypoint_idx = None
        self.last_waypoint_idx = None
        self.target_positions = None

        # --- State Tracking (åˆå§‹åŒ–ä¸ºç©º) ---
        self.dist_to_target = None
        self.reached_waypoint = None
        self.consecutive_successes = None
        self.collision_detected = None
        self.robot_non_foot_indices = None

        # --- è°ƒç”¨çˆ¶ç±» G1CurriculumBase åˆå§‹åŒ– ---
        # è¿™ä¼šè®¾ç½®å¥½ gym, sim, device, åŸºç¡€ç¼“å†²åŒºï¼ˆåŸºäºcfgï¼‰, viewer
        # *ä½†æ˜¯* ä¸ä¼šè°ƒç”¨ prepare_sim æˆ– init_buffers
        # å®ƒä¼šè°ƒç”¨è¢«æˆ‘ä»¬é‡å†™çš„ create_sim -> _load_kitchen_assets -> _create_envs
        super().__init__(cfg, sim_params, physics_engine, sim_device, headless, gym_handle=gym_handle, sim_handle=sim_handle)

        # --- æ£€æŸ¥create_simå’Œcreate_envsæ˜¯å¦è¢«è°ƒç”¨ ---
        print(f"çˆ¶ç±»__init__æ‰§è¡Œå®Œæˆ.")
        print(f"create_simæ˜¯å¦è¢«è°ƒç”¨: {self.create_sim_called}")
        print(f"create_envsæ˜¯å¦è¢«è°ƒç”¨: {self.create_envs_called}")
        print(f"ç¯å¢ƒæ˜¯å¦å·²åˆ›å»º: {'æ˜¯' if hasattr(self, 'envs') and len(self.envs) > 0 else 'å¦'}")


        # --- åç»­åˆå§‹åŒ– (åœ¨ç¯å¢ƒå’Œ Actors åˆ›å»ºå, ä¸” prepare_sim è°ƒç”¨å) ---
        # æ³¨æ„: _init_buffers å’Œ _prepare_reward_function ä¼šåœ¨çˆ¶ç±»çš„ __init__ æœ«å°¾è¢«è°ƒç”¨
        # å› æ­¤å¯¼èˆªç‚¹å’Œç¢°æ’ç´¢å¼•çš„åˆå§‹åŒ–éœ€è¦åœ¨è¿™ä¹‹åï¼Œæˆ–è€…åœ¨ _init_buffers ä¸­å¤„ç†

        # ç°åœ¨ _init_buffers å·²è¢«è°ƒç”¨ (å› ä¸ºå®ƒåœ¨çˆ¶ç±» __init__ æœ«å°¾)
        # æˆ‘ä»¬å¯ä»¥å®‰å…¨åœ°åˆå§‹åŒ–å¯¼èˆªçŠ¶æ€äº†
        self._initialize_kitchen_waypoints()
        if self.waypoint_positions is not None and len(self.active_waypoint_indices) > 0:
             num_active_waypoints = len(self.active_waypoint_indices)
             self.current_waypoint_idx = torch.randint(0, num_active_waypoints, (self.num_envs,), device=self.device, dtype=torch.long)
             self.current_waypoint_idx = torch.tensor(self.active_waypoint_indices, device=self.device)[self.current_waypoint_idx]
             self.last_waypoint_idx = self.current_waypoint_idx.clone()
             self.target_positions = self.waypoint_positions[self.current_waypoint_idx]
             self.dist_to_target = torch.full((self.num_envs,), float('inf'), device=self.device)
             self.reached_waypoint = torch.zeros(self.num_envs, dtype=torch.bool, device=self.device)
             self.consecutive_successes = torch.zeros(self.num_envs, dtype=torch.long, device=self.device)
             self.collision_detected = torch.zeros(self.num_envs, dtype=torch.bool, device=self.device)
             print(f"  å¯¼èˆªåˆå§‹åŒ–å®Œæˆã€‚æ¿€æ´»å¯¼èˆªç‚¹æ•°: {num_active_waypoints}")
        else:
             print("âš ï¸ å¯¼èˆªç‚¹åˆå§‹åŒ–å¤±è´¥æˆ–æ— æ¿€æ´»å¯¼èˆªç‚¹ã€‚å¯¼èˆªåŠŸèƒ½å°†å—é™ã€‚")
             # Set defaults
             self.current_waypoint_idx = torch.zeros(self.num_envs, dtype=torch.long, device=self.device)
             self.last_waypoint_idx = self.current_waypoint_idx.clone()
             self.target_positions = torch.zeros((self.num_envs, 3), device=self.device)
             self.dist_to_target = torch.full((self.num_envs,), float('inf'), device=self.device)
             self.reached_waypoint = torch.zeros(self.num_envs, dtype=torch.bool, device=self.device)
             self.consecutive_successes = torch.zeros(self.num_envs, dtype=torch.long, device=self.device)
             self.collision_detected = torch.zeros(self.num_envs, dtype=torch.bool, device=self.device)

        # è·å–ç”¨äºç¢°æ’æ£€æµ‹çš„ body indices (åº”åœ¨ _init_buffers å)
        self._get_collision_body_indices()

        # --- éªŒè¯è§‚æµ‹/åŠ¨ä½œç»´åº¦ (åœ¨ _init_buffers ä¹‹åè¿›è¡Œ) ---
        if self.num_actions != 43: print(f"âŒ ERROR: G1KitchenNavigation - num_actions ({self.num_actions}) != 43")
        expected_obs_dim = getattr(self.cfg.env, 'num_observations', 143) # Read from config
        if self.obs_buf.shape[1] != expected_obs_dim: print(f"âŒ ERROR: G1KitchenNavigation - obs_buf dim ({self.obs_buf.shape[1]}) != configured ({expected_obs_dim})")
        expected_priv_obs_dim = getattr(self.cfg.env, 'num_privileged_obs', 148)
        if self.privileged_obs_buf is not None and self.privileged_obs_buf.shape[1] != expected_priv_obs_dim: print(f"âŒ ERROR: G1KitchenNavigation - priv_obs_buf dim ({self.privileged_obs_buf.shape[1]}) != configured ({expected_priv_obs_dim})")

        print("--- G1KitchenNavigation Initialized Successfully ---")



    def _load_kitchen_assets(self):
        """åŠ è½½æ‰€æœ‰Kitchenèµ„äº§ï¼Œåœ¨åˆ›å»ºç¯å¢ƒä¹‹å‰"""
        print("ğŸ” å¼€å§‹åŠ è½½Kitchenèµ„äº§...")
        asset_root = "/home/blake/kitchen-worlds/assets/models/"
        lisdf_path = "/home/blake/kitchen-worlds/assets/scenes/kitchen_basics.lisdf"
        pose_data = parse_lisdf(lisdf_path)

        # åŠ è½½æ‰€æœ‰URDFèµ„äº§
        for urdf_path, data in pose_data.items():
            urdf_relative_path = os.path.relpath(urdf_path, asset_root)
            if not os.path.exists(urdf_path):
                print(f"âš ï¸ Warning: URDF æ–‡ä»¶ä¸å­˜åœ¨: {urdf_path}")
                continue

            pose = data["pose"]
            scale = data["scale"]

            asset_options = gymapi.AssetOptions()
            asset_options.fix_base_link = True
            asset_options.disable_gravity = False
            asset_options.use_mesh_materials = True
            asset_options.override_com = True
            asset_options.override_inertia = True

            # ä¿®æ”¹ç¢°æ’ç”Ÿæˆé€‰é¡¹ï¼Œé¿å…å‡¸åŒ…åˆ†è§£é”™è¯¯
            asset_options.convex_decomposition_from_submeshes = False  # ç¦ç”¨ä»å­ç½‘æ ¼åˆ›å»ºå‡¸åŒ…
            asset_options.vhacd_enabled = False  # ç¦ç”¨VHACD
            asset_options.mesh_normal_mode = gymapi.COMPUTE_PER_VERTEX
            asset_options.thickness = 0.01  # å¢åŠ åšåº¦å¯èƒ½æœ‰åŠ©äºç¨³å®šæ€§

            try:
                object_asset = self.gym.load_asset(self.sim, asset_root, urdf_relative_path, asset_options)
                if object_asset is None:
                    print(f"âŒ ERROR: æ— æ³•åŠ è½½ URDF: {urdf_relative_path}")
                    continue

                self.kitchen_assets[urdf_relative_path] = object_asset
                self.kitchen_poses[urdf_relative_path] = pose
                # å­˜å‚¨scaleä¿¡æ¯
                self.kitchen_scales = getattr(self, 'kitchen_scales', {})
                self.kitchen_scales[urdf_relative_path] = scale
                print(f"âœ… æˆåŠŸåŠ è½½: {urdf_relative_path} (Scale: {scale})")
            except Exception as e:
                print(f"âŒ åŠ è½½'{urdf_relative_path}'æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                # å¦‚æœåŠ è½½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ›´ç®€å•çš„ç¢°æ’è®¾ç½®
                try:
                    print(f"ğŸ”„ å°è¯•ä½¿ç”¨ç®€åŒ–é€‰é¡¹é‡æ–°åŠ è½½'{urdf_relative_path}'")
                    asset_options.convex_decomposition_from_submeshes = False
                    asset_options.vhacd_enabled = False
                    asset_options.default_dof_drive_mode = gymapi.DOF_MODE_NONE
                    asset_options.use_mesh_materials = False
                    # ä½¿ç”¨éå¸¸ç®€å•çš„ç¢°æ’æ¨¡å‹
                    asset_options.create_convex_meshes = False
                    asset_options.replace_cylinder_with_capsule = True

                    object_asset = self.gym.load_asset(self.sim, asset_root, urdf_relative_path, asset_options)
                    if object_asset is not None:
                        self.kitchen_assets[urdf_relative_path] = object_asset
                        self.kitchen_poses[urdf_relative_path] = pose
                        # å­˜å‚¨scaleä¿¡æ¯
                        self.kitchen_scales = getattr(self, 'kitchen_scales', {})
                        self.kitchen_scales[urdf_relative_path] = scale
                        print(f"âœ… æˆåŠŸä½¿ç”¨ç®€åŒ–é€‰é¡¹åŠ è½½: {urdf_relative_path} (Scale: {scale})")
                except Exception as e2:
                    print(f"âŒ ç®€åŒ–åŠ è½½ä»ç„¶å¤±è´¥: {e2}")
                    continue

    def _add_kitchen_actors_to_envs(self):
        """å‘ç°æœ‰ç¯å¢ƒæ·»åŠ å¨æˆ¿Actor"""
        if not self.kitchen_assets:
            print("âŒ æ²¡æœ‰å¨æˆ¿èµ„äº§å¯æ·»åŠ ï¼")
            return

        print(f"å‡†å¤‡å‘ {self.num_envs} ä¸ªç¯å¢ƒæ·»åŠ å¨æˆ¿Actor...")

        # å¨æˆ¿åŸºå‡†åç§»ï¼ˆä¸æ‚¨çš„kitchen_env.pyä¸­ç›¸ä¼¼ï¼‰
        kitchen_base_offset = torch.tensor([2.3, 4.7, -0.002], device=self.device)

        # ç¯å¢ƒé—´è·æ”¾å¤§å› å­ï¼ˆä»kitchen_env.pyå€Ÿé‰´ï¼‰
        spacing_factor = 5.0

        # ä¸ºæ¯ä¸ªç¯å¢ƒæ·»åŠ å¨æˆ¿Actor
        total_added = 0
        for i, env_handle in enumerate(self.envs):
            # è¿™é‡Œåº”ç”¨äº†spacing_factorï¼Œä¸kitchen_env.pyä¿æŒä¸€è‡´
            env_origin = self.env_origins[i].clone() * spacing_factor

            successful_kitchen_actors = []
            for asset_key, asset in self.kitchen_assets.items():
                # è·å–èµ„äº§å§¿æ€å’Œç¼©æ”¾
                pose_info = self.kitchen_poses[asset_key]
                scale = self.kitchen_scales.get(asset_key, 1.0)

                # åˆ›å»ºå˜æ¢
                transform = gymapi.Transform()
                transform.p = gymapi.Vec3(
                    float(pose_info.pos[0]) - kitchen_base_offset[0] + env_origin[0],
                    float(pose_info.pos[1]) - kitchen_base_offset[1] + env_origin[1],
                    float(pose_info.pos[2]) - kitchen_base_offset[2] + env_origin[2]
                )
                transform.r = gymapi.Quat(
                    float(pose_info.quat_wxyz[1]),
                    float(pose_info.quat_wxyz[2]),
                    float(pose_info.quat_wxyz[3]),
                    float(pose_info.quat_wxyz[0])
                )

                # åˆ›å»ºActor
                actor_name = f"kitchen_{i}_{os.path.basename(asset_key)}"
                kitchen_actor_handle = self.gym.create_actor(
                    env_handle,
                    asset,
                    transform,
                    actor_name,
                    2,  # ç¢°æ’ç»„ï¼ˆä¸kitchen_env.pyä¸€è‡´ï¼‰
                    1  # ç¢°æ’è¿‡æ»¤å™¨
                )

                if kitchen_actor_handle != gymapi.INVALID_HANDLE:
                    # è®¾ç½®ç¼©æ”¾
                    try:
                        if isinstance(scale, (list, tuple)) or hasattr(scale, 'tolist'):
                            scale_value = float(scale[0] if isinstance(scale, (list, tuple)) else scale.tolist()[0])
                        else:
                            scale_value = float(scale)
                        self.gym.set_actor_scale(env_handle, kitchen_actor_handle, scale_value)
                    except Exception as e:
                        print(f"âš ï¸ è®¾ç½®ç¼©æ”¾å¤±è´¥ ({asset_key}): {e}")

                    successful_kitchen_actors.append(kitchen_actor_handle)
                    total_added += 1

            self.kitchen_actors_by_env[i] = successful_kitchen_actors

        print(f"âœ… æˆåŠŸæ·»åŠ äº† {total_added} ä¸ªå¨æˆ¿Actoråˆ° {self.num_envs} ä¸ªç¯å¢ƒä¸­")



    # --- é‡å†™ Simulation å’Œ Environment åˆ›å»º ---

    def create_sim(self):
        """ é‡å†™ create_sim ä»¥æŒ‰æ­£ç¡®é¡ºåºåŠ è½½ Kitchen.
            è¿™ä¸ªæ–¹æ³•å®é™…ä¸Šç”±çˆ¶ç±» (LeggedRobot) çš„ __init__ è°ƒç”¨ï¼Œ
            è¿™é‡Œåªæ˜¯ä¸ºäº†æ˜ç¡®é€»è¾‘é¡ºåºã€‚
            å®é™…çš„ Sim åˆ›å»ºç”±å¤–éƒ¨ (train_curriculum.py) å®Œæˆã€‚
            è¿™ä¸ªæ–¹æ³•ç°åœ¨è´Ÿè´£åˆ›å»ºåœ°é¢å’Œè°ƒç”¨ _create_envsã€‚
        """
        print("--- create_sim (G1KitchenNavigation) ---")
        self.create_sim_called = True
        # Ground plane/Terrain should be created *before* actors

        if not hasattr(self.sim_params, "up_axis"):
            self.sim_params.up_axis = 2  # Z-up
        if not hasattr(self.sim_params, "gravity"):
            self.sim_params.gravity = gymapi.Vec3(0.0, 0.0, -9.81)  # æ­£å¸¸é‡åŠ›

        # ç¡®ä¿ç¢°æ’å‚æ•°åˆç†
        if hasattr(self.sim_params, "physx"):
            self.sim_params.physx.contact_offset = 0.01  # å¢åŠ ç¢°æ’åç§»é‡
            self.sim_params.physx.solver_type = 1  # ä½¿ç”¨PGSæ±‚è§£å™¨å¯èƒ½æ›´ç¨³å®š

        if hasattr(self, '_create_terrain'): self._create_terrain()
        else: self._create_ground_plane()
        print("  âœ… Ground/Terrain created.")
        print("  å³å°†è°ƒç”¨ _load_kitchen_assets")
        self._load_kitchen_assets()  # åŠ è½½ Kitchen èµ„äº§
        print("  _load_kitchen_assets è°ƒç”¨å®Œæˆ")
        self._create_envs() # åˆ›å»ºç¯å¢ƒï¼ˆåŒ…æ‹¬æœºå™¨äººå’Œ Kitchen actorsï¼‰
        # prepare_sim is called AFTER _create_envs in the parent __init__

        return self.sim

    def _create_envs(self):
        """ é‡å†™ç¯å¢ƒåˆ›å»ºï¼Œæ·»åŠ  Kitchen Actors """
        print("--- _create_envs (G1KitchenNavigation) ---")
        self.create_envs_called = True

        # --- ç¡®ä¿å¨æˆ¿èµ„äº§å·²åŠ è½½ ---
        if not self.kitchen_assets:
            print("  å¨æˆ¿èµ„äº§å°šæœªåŠ è½½ï¼Œå…ˆåŠ è½½å¨æˆ¿èµ„äº§...")
            self._load_kitchen_assets()

        # --- 1. åŠ è½½æœºå™¨äººèµ„æº (ä¸çˆ¶ç±» LeggedRobot ä¸€è‡´) ---
        # Define G1_ROOT_DIR locally if needed
        G1_ROOT_DIR_LOCAL = os.path.dirname(
            os.path.dirname(os.path.dirname(os.path.abspath(__file__)))) if '__file__' in globals() else ""
        asset_path = self.cfg.asset.file.format(G1_ROOT_DIR=G1_ROOT_DIR_LOCAL)
        asset_root = os.path.dirname(asset_path)
        asset_file = os.path.basename(asset_path)
        asset_options = gymapi.AssetOptions()
        asset_options.default_dof_drive_mode = self.cfg.asset.default_dof_drive_mode
        asset_options.collapse_fixed_joints = self.cfg.asset.collapse_fixed_joints
        asset_options.replace_cylinder_with_capsule = self.cfg.asset.replace_cylinder_with_capsule
        asset_options.flip_visual_attachments = self.cfg.asset.flip_visual_attachments
        asset_options.fix_base_link = self.cfg.asset.fix_base_link
        asset_options.density = self.cfg.asset.density
        asset_options.angular_damping = self.cfg.asset.angular_damping
        asset_options.linear_damping = self.cfg.asset.linear_damping
        asset_options.max_angular_velocity = self.cfg.asset.max_angular_velocity
        asset_options.max_linear_velocity = self.cfg.asset.max_linear_velocity
        asset_options.armature = self.cfg.asset.armature
        asset_options.thickness = self.cfg.asset.thickness
        asset_options.disable_gravity = self.cfg.asset.disable_gravity

        print(f"  åŠ è½½æœºå™¨äººèµ„æº: {asset_file}")
        robot_asset = self.gym.load_asset(self.sim, asset_root, asset_file, asset_options)
        if robot_asset is None: raise RuntimeError("Failed to load robot asset.")
        self.num_dof = self.gym.get_asset_dof_count(robot_asset)  # Robot DoFs (43)
        self.num_bodies = self.gym.get_asset_rigid_body_count(robot_asset)  # Robot Bodies
        if self.cfg.env.num_actions != self.num_dof:
            print(
                f"âš ï¸ _create_envs Warning: cfg.env.num_actions ({self.cfg.env.num_actions}) != asset num_dof ({self.num_dof}). Overriding.")
            self.cfg.env.num_actions = self.num_dof
        self.num_actions = self.num_dof
        print(f"  æœºå™¨äººèµ„æºåŠ è½½: Num DoF={self.num_dof}, Num Bodies={self.num_bodies}")

        dof_props_asset = self.gym.get_asset_dof_properties(robot_asset)
        rigid_shape_props_asset = self.gym.get_asset_rigid_shape_properties(robot_asset)
        body_names = self.gym.get_asset_rigid_body_names(robot_asset)
        self.dof_names = self.gym.get_asset_dof_names(robot_asset)
        feet_names = [s for s in body_names if self.cfg.asset.foot_name in s]
        penalized_contact_names = []
        for name in self.cfg.asset.penalize_contacts_on: penalized_contact_names.extend(
            [s for s in body_names if name in s])
        termination_contact_names = []
        for name in self.cfg.asset.terminate_after_contacts_on: termination_contact_names.extend(
            [s for s in body_names if name in s])

        # --- 2. åˆå§‹åŒ–åˆ—è¡¨ ---
        self.envs = []
        self.env_actor_handles = []  # åµŒå¥—åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ å­˜å‚¨ä¸€ä¸ªç¯å¢ƒçš„æ‰€æœ‰actors
        self.kitchen_actors_by_env = [[] for _ in range(self.num_envs)]

        # --- 3. è·å–åŸç‚¹å’Œåˆå§‹çŠ¶æ€ ---
        self._get_env_origins()
        base_init_state_list = self.cfg.init_state.pos + self.cfg.init_state.rot + self.cfg.init_state.lin_vel + self.cfg.init_state.ang_vel
        self.base_init_state = to_torch(base_init_state_list, device=self.device, requires_grad=False)
        robot_start_pose = gymapi.Transform()

        # --- 4. å¾ªç¯åˆ›å»ºç¯å¢ƒ ---
        env_lower = gymapi.Vec3(0., 0., 0.);
        env_upper = gymapi.Vec3(0., 0., 0.)
        kitchen_base_offset = torch.tensor(getattr(self.cfg.asset, 'kitchen_origin_offset', [0.0, 0.0, 0.0]),
                                           device=self.device)
        print(f"  Creating {self.num_envs} environments with Kitchen...")

        for i in range(self.num_envs):
            # åˆ›å»ºå•ä¸ªç¯å¢ƒ
            env_handle = self.gym.create_env(self.sim, env_lower, env_upper, int(np.sqrt(self.num_envs)))
            if env_handle == gymapi.INVALID_HANDLE: raise RuntimeError(f"Failed to create env {i}")
            self.envs.append(env_handle)
            env_actor_handles = []  # å½“å‰ç¯å¢ƒçš„æ‰€æœ‰actorå¥æŸ„

            # è®¾ç½®æœºå™¨äººå§¿æ€
            env_origin = self.env_origins[i]
            robot_start_pose.p = gymapi.Vec3(env_origin[0] + self.base_init_state[0],
                                             env_origin[1] + self.base_init_state[1],
                                             env_origin[2] + self.base_init_state[2])
            robot_start_pose.r = gymapi.Quat(*self.base_init_state[3:7])

            # åˆ›å»ºæœºå™¨äººactor
            rigid_shape_props = self._process_rigid_shape_props(rigid_shape_props_asset, i)
            robot_actor_handle = self.gym.create_actor(env_handle, robot_asset, robot_start_pose, self.cfg.asset.name,
                                                       0,  # ç¢°æ’ç»„0ç”¨äºæœºå™¨äºº
                                                       self.cfg.asset.self_collisions, 0)  # è¿‡æ»¤å™¨0
            if robot_actor_handle == gymapi.INVALID_HANDLE: raise RuntimeError(
                f"Failed to create robot actor in env {i}")
            env_actor_handles.append(robot_actor_handle)

            # è®¾ç½®æœºå™¨äººå±æ€§
            dof_props = self._process_dof_props(dof_props_asset, i)
            self.gym.set_actor_dof_properties(env_handle, robot_actor_handle, dof_props)
            body_props = self.gym.get_actor_rigid_body_properties(env_handle, robot_actor_handle)
            if body_props:
                processed_body_props = self._process_rigid_body_props(body_props, i)
                self.gym.set_actor_rigid_body_properties(env_handle, robot_actor_handle, processed_body_props,
                                                         recomputeInertia=True)

            # ç«‹å³åœ¨åŒä¸€ç¯å¢ƒä¸­åˆ›å»ºæ‰€æœ‰å¨æˆ¿actor
            kitchen_actors_in_env = []
            for asset_key, asset in self.kitchen_assets.items():
                kitchen_handle = self._add_kitchen_actor(i, env_handle, asset_key, asset, env_origin,
                                                         kitchen_base_offset)
                if kitchen_handle != gymapi.INVALID_HANDLE:
                    kitchen_actors_in_env.append(kitchen_handle)
                    env_actor_handles.append(kitchen_handle)

            # ä¸ºå½“å‰ç¯å¢ƒå­˜å‚¨å¨æˆ¿actorå¥æŸ„
            self.kitchen_actors_by_env[i] = kitchen_actors_in_env

            # å°†å½“å‰ç¯å¢ƒçš„æ‰€æœ‰actorå¥æŸ„å­˜å…¥åµŒå¥—åˆ—è¡¨
            self.env_actor_handles.append(env_actor_handles)

        # --- 5. æ„å»ºæ‰å¹³åŒ–çš„actor_handlesåˆ—è¡¨ ---
        flat_actor_handles = []
        for env_actors in self.env_actor_handles:
            flat_actor_handles.extend(env_actors)
        self.actor_handles = flat_actor_handles

        print(f"  åˆ›å»ºäº† {len(self.envs)} ä¸ªç¯å¢ƒ, æ€»å…± {len(self.actor_handles)} ä¸ªactors")

        # --- 6. è®¾ç½®ç´¢å¼• (åœ¨æ‰€æœ‰ Actors åˆ›å»ºå) ---
        if self.actor_handles:
            # è·å–ç¬¬ä¸€ä¸ªç¯å¢ƒçš„æœºå™¨äººactorå¥æŸ„
            first_robot_handle = self.env_actor_handles[0][0]  # ç¬¬ä¸€ä¸ªç¯å¢ƒçš„ç¬¬ä¸€ä¸ªactoræ˜¯æœºå™¨äºº
            self.dof_props_storage = self.gym.get_actor_dof_properties(self.envs[0], first_robot_handle)

            # è®¾ç½®feet_indices
            self.feet_indices = torch.zeros(len(feet_names), dtype=torch.long, device=self.device, requires_grad=False)
            for idx, name in enumerate(feet_names):
                handle = self.gym.find_actor_rigid_body_handle(self.envs[0], first_robot_handle, name)
                if handle == gymapi.INVALID_HANDLE: print(f"âš ï¸ Warning: Foot body '{name}' not found.")
                self.feet_indices[idx] = handle  # Store local body index

            # Penalised/Termination indices (local to robot)
            self.penalised_contact_indices = torch.zeros(len(penalized_contact_names), dtype=torch.long,
                                                         device=self.device, requires_grad=False)
            for idx, name in enumerate(penalized_contact_names):
                handle = self.gym.find_actor_rigid_body_handle(self.envs[0], first_robot_handle, name)
                if handle == gymapi.INVALID_HANDLE: print(f"âš ï¸ Warning: Penalised body '{name}' not found.")
                self.penalised_contact_indices[idx] = handle

            self.termination_contact_indices = torch.zeros(len(termination_contact_names), dtype=torch.long,
                                                           device=self.device, requires_grad=False)
            for idx, name in enumerate(termination_contact_names):
                handle = self.gym.find_actor_rigid_body_handle(self.envs[0], first_robot_handle, name)
                if handle == gymapi.INVALID_HANDLE: print(f"âš ï¸ Warning: Termination body '{name}' not found.")
                self.termination_contact_indices[idx] = handle

            # Store robot non-foot indices (local)
            self.robot_non_foot_indices = [j for j in range(self.num_bodies) if
                                           j not in self.feet_indices.cpu().tolist()]
            print(f"  Feet indices (local): {self.feet_indices.cpu().tolist()}")
        else:
            print("âŒ ERROR: No actors created.")
            # Init empty tensors
            self.feet_indices = torch.tensor([], dtype=torch.long, device=self.device)
            self.penalised_contact_indices = torch.tensor([], dtype=torch.long, device=self.device)
            self.termination_contact_indices = torch.tensor([], dtype=torch.long, device=self.device)
            self.robot_non_foot_indices = []

        print(f"--- _create_envs (G1KitchenNavigation) Done ---")

    def _add_kitchen_actor(self, env_idx, env_handle, asset_key, asset, env_origin, kitchen_base_offset):
        """ Helper to add a single kitchen actor, returns handle """
        pose_info = self.kitchen_poses[asset_key]
        scale = self.kitchen_scales.get(asset_key, 1.0)

        # è®¡ç®—ä½ç½®
        transform = gymapi.Transform()
        transform.p = gymapi.Vec3(env_origin[0] + (pose_info.pos[0] - kitchen_base_offset[0]),
                                  env_origin[1] + (pose_info.pos[1] - kitchen_base_offset[1]),
                                  env_origin[2] + (pose_info.pos[2] - kitchen_base_offset[2]))
        transform.r = gymapi.Quat(pose_info.quat_wxyz[1], pose_info.quat_wxyz[2], pose_info.quat_wxyz[3],
                                  pose_info.quat_wxyz[0])

        # åˆ›å»ºActor
        kitchen_actor_handle = self.gym.create_actor(env_handle, asset, transform,
                                                     f"kitchen_{env_idx}_{os.path.basename(asset_key)}",
                                                     1,  # Collision group
                                                     0)  # Collision filter

        if kitchen_actor_handle == gymapi.INVALID_HANDLE:
            print(f"    âŒ ERROR: Failed to create kitchen actor '{asset_key}'")
            return gymapi.INVALID_HANDLE

        # é€‚å½“åº”ç”¨ç¼©æ”¾ - ä½¿ç”¨ç¬¬ä¸€ä¸ªå€¼ä½œä¸ºç»Ÿä¸€ç¼©æ”¾
        try:
            # ç¡®ä¿scaleæ˜¯ä¸€ä¸ªæµ®ç‚¹æ•°
            if isinstance(scale, (list, tuple, np.ndarray)) or hasattr(scale, 'tolist'):
                scale_value = float(scale[0] if isinstance(scale, (list, tuple)) else scale.tolist()[0])
            else:
                scale_value = float(scale)

            self.gym.set_actor_scale(env_handle, kitchen_actor_handle, scale_value)
        except Exception as e:
            print(f"    âš ï¸ Warning: Failed to apply scale {scale} to '{asset_key}': {e}")

        return kitchen_actor_handle

    def _reset_dofs(self, env_ids):
        """ åœ¨G1KitchenNavigationä¸­é‡å†™DOFé‡ç½®ä»¥é€‚åº”å¤æ‚ç¯å¢ƒ """
        if len(env_ids) == 0:
            return

        # ç”Ÿæˆéšæœºä½ç½®å’Œé›¶é€Ÿåº¦ï¼Œä¸åŸºç±»ç›¸åŒ
        new_dof_pos = self.default_dof_pos * torch_rand_float(0.5, 1.5, (len(env_ids), self.num_dof),
                                                              device=self.device)
        new_dof_vel = torch.zeros((len(env_ids), self.num_dof), device=self.device)

        # æ›´æ–°å†…éƒ¨ç¼“å†²åŒº
        self.dof_pos[env_ids] = new_dof_pos
        self.dof_vel[env_ids] = new_dof_vel

        # å¯¹äºå¨æˆ¿ç¯å¢ƒï¼Œç›´æ¥ä½¿ç”¨ç´¢å¼•æ›´æ–°æ–¹æ³•ï¼Œä¸å°è¯•è§†å›¾æ“ä½œ
        # å› ä¸ºæˆ‘ä»¬çŸ¥é“åœ¨å¤šActorç¯å¢ƒä¸­è§†å›¾æ“ä½œä¼šå¤±è´¥
        dof_state_cpu = self.dof_state.cpu().numpy()

        # å¯¹æ¯ä¸ªç¯å¢ƒå•ç‹¬æ›´æ–°
        for i, env_id in enumerate(env_ids.cpu().numpy()):
            # è·å–æ­¤ç¯å¢ƒçš„DOFèµ·å§‹ç´¢å¼•
            if env_id < len(self.robot_dof_start_indices):
                start_idx = self.robot_dof_start_indices[env_id]

                # æ›´æ–°ä½ç½®å’Œé€Ÿåº¦
                for j in range(self.num_dof):
                    dof_state_cpu[start_idx + j, 0] = new_dof_pos[i, j].cpu().numpy()
                    dof_state_cpu[start_idx + j, 1] = new_dof_vel[i, j].cpu().numpy()

        # å°†æ›´æ–°åçš„çŠ¶æ€å¤åˆ¶å›GPU
        self.dof_state.copy_(torch.tensor(dof_state_cpu, device=self.device))

        # ä½¿ç”¨å…¨å±€å¼ é‡æ›´æ–°
        try:
            self.gym.set_dof_state_tensor(self.sim, gymtorch.unwrap_tensor(self.dof_state))
            return  # æˆåŠŸåˆ™ç›´æ¥è¿”å›
        except Exception as e:
            print(f"âš ï¸ set_dof_state_tensorå¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•: {e}")

        # å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨å•ä¸ªç¯å¢ƒAPIé€ä¸ªæ›´æ–°
        for i, env_id in enumerate(env_ids.cpu().numpy()):
            if env_id >= len(self.envs):
                continue

            # æ‰¾åˆ°æ­¤ç¯å¢ƒçš„æœºå™¨äººactorå¥æŸ„
            robot_handle = self.env_actor_handles[env_id][0]  # ç¬¬ä¸€ä¸ªactoræ˜¯æœºå™¨äºº

            # åˆ›å»ºnumpyæ•°ç»„ä»¥ä¼ é€’ç»™gym API
            dof_states = np.zeros((self.num_dof, 2), dtype=np.float32)
            dof_states[:, 0] = new_dof_pos[i].cpu().numpy()
            dof_states[:, 1] = new_dof_vel[i].cpu().numpy()

            # ä½¿ç”¨å•ä¸ªç¯å¢ƒAPIè®¾ç½®DOFçŠ¶æ€
            try:
                self.gym.set_actor_dof_states(
                    self.envs[env_id],
                    robot_handle,
                    dof_states,
                    gymapi.STATE_ALL
                )
            except Exception as e3:
                print(f"âŒ ç¯å¢ƒ {env_id} çš„å•ä¸ªç¯å¢ƒAPIä¹Ÿå¤±è´¥: {e3}")

    def _manual_dof_update(self):
        """å®ç°æ‰‹åŠ¨DOFçŠ¶æ€æ›´æ–°ï¼Œç¡®ä¿æ²¡æœ‰NaNæˆ–Inf"""
        try:
            # åˆ·æ–°DOFçŠ¶æ€å¼ é‡
            self.gym.refresh_dof_state_tensor(self.sim)

            # å¯¹åº”æ¯ä¸ªç¯å¢ƒ
            for i in range(self.num_envs):
                if i >= len(self.robot_dof_start_indices):
                    continue

                start_idx = self.robot_dof_start_indices[i]
                end_idx = start_idx + self.num_dof

                if end_idx > self.dof_state.shape[0]:
                    continue

                # æå–DOFä½ç½®å’Œé€Ÿåº¦
                pos = self.dof_state[start_idx:end_idx, 0].clone()
                vel = self.dof_state[start_idx:end_idx, 1].clone()

                # æ£€æŸ¥å¹¶å¤„ç†éæ³•å€¼
                pos = torch.where(torch.isnan(pos) | torch.isinf(pos),
                                  torch.zeros_like(pos), pos)
                vel = torch.where(torch.isnan(vel) | torch.isinf(vel),
                                  torch.zeros_like(vel), vel)

                # æ›´æ–°ä½ç½®å’Œé€Ÿåº¦
                self.dof_pos[i] = pos
                self.dof_vel[i] = vel

            return True
        except Exception as e:
            print(f"æ‰‹åŠ¨DOFæ›´æ–°å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False



    # --- é‡å†™ Buffer åˆå§‹åŒ–ä»¥é€‚åº”å¤šä¸ª Actor ---
    def _init_buffers(self):
        """ é‡å†™ _init_buffers ä»¥å¤„ç†åŒ…å« Kitchen Actors çš„ç¯å¢ƒ """
        print("--- _init_buffers (G1KitchenNavigation) ---")

        # --- 1. è·å– Gym å¼ é‡ (åœ¨ prepare_sim åè°ƒç”¨) ---
        actor_root_state = self.gym.acquire_actor_root_state_tensor(self.sim)
        dof_state_tensor = self.gym.acquire_dof_state_tensor(self.sim)
        net_contact_forces = self.gym.acquire_net_contact_force_tensor(self.sim)
        rigid_body_state_tensor = self.gym.acquire_rigid_body_state_tensor(self.sim)

        for name, tensor in zip(["actor_root_state", "dof_state", "net_contact_forces", "rigid_body_state"],
                                [actor_root_state, dof_state_tensor, net_contact_forces, rigid_body_state_tensor]):
             if tensor is None: raise RuntimeError(f"Failed to acquire {name}_tensor.")

        self.gym.refresh_actor_root_state_tensor(self.sim)
        self.gym.refresh_dof_state_tensor(self.sim)
        self.gym.refresh_net_contact_force_tensor(self.sim)
        self.gym.refresh_rigid_body_state_tensor(self.sim)

        # --- 2. åŒ…è£…åŸºç¡€å¼ é‡ ---
        self.root_states = gymtorch.wrap_tensor(actor_root_state)         # Shape: [num_envs * actors_per_env, 13]
        self.dof_state = gymtorch.wrap_tensor(dof_state_tensor)           # Shape: [total_sim_dofs, 2]
        self.rigid_body_states = gymtorch.wrap_tensor(rigid_body_state_tensor) # Shape: [total_sim_bodies, 13]
        self.contact_forces_raw = gymtorch.wrap_tensor(net_contact_forces) # Raw shape

        # --- 3. ç¡®å®š Actor/DoF/Body ç»“æ„ ---
        self.actors_per_env = self.gym.get_actor_count(self.envs[0]) # Actors per env
        self.sim_total_dofs = self.gym.get_sim_dof_count(self.sim)
        self.sim_total_bodies = self.gym.get_sim_rigid_body_count(self.sim)
        self.dofs_per_env = self.sim_total_dofs // self.num_envs
        self.bodies_per_env = self.sim_total_bodies // self.num_envs

        print(f"  Buffer Info: num_envs={self.num_envs}, actors_per_env={self.actors_per_env}")
        print(f"               dofs_per_env={self.dofs_per_env}, bodies_per_env={self.bodies_per_env}")
        print(f"  Raw Shapes: root={self.root_states.shape}, dof={self.dof_state.shape}, rigid={self.rigid_body_states.shape}, contact={self.contact_forces_raw.shape}")

        # --- 4. åˆ›å»ºæœºå™¨äººç‰¹å®šçš„è§†å›¾ ---
        self.robot_root_indices = torch.arange(0, self.root_states.shape[0], self.actors_per_env, device=self.device, dtype=torch.long)
        self.robot_root_states = self.root_states[self.robot_root_indices]
        self.base_pos = self.robot_root_states[:, 0:3]
        self.base_quat = self.robot_root_states[:, 3:7]

        # --- 5. åˆ›å»ºæœºå™¨äºº DoF çŠ¶æ€çš„ç¼“å†²åŒºå’Œç´¢å¼• ---
        # (self.num_dof is the robot's DoF count, e.g., 43)
        self.dof_pos = torch.zeros(self.num_envs, self.num_dof, device=self.device, dtype=torch.float)
        self.dof_vel = torch.zeros(self.num_envs, self.num_dof, device=self.device, dtype=torch.float)
        self.manual_dof_update = True # Always update manually in multi-actor case

        # Calculate global indices for robot DoFs
        self.robot_dof_start_indices = []
        current_dof_start = 0
        for i in range(self.num_envs):
            self.robot_dof_start_indices.append(current_dof_start)
            # In this env, robot is actor 0, assume its DoFs come first
            current_dof_start += self.dofs_per_env # Increment by total DoFs in the env

        self.robot_dof_start_indices = []
        current_dof_start = 0
        for i in range(self.num_envs):
            self.robot_dof_start_indices.append(current_dof_start)
            # In this env, robot is actor 0, assume its DoFs come first
            current_dof_start += self.dofs_per_env  # Increment by total DoFs in the env

        print(f"  åˆå§‹åŒ– robot_dof_start_indices (num_envs={self.num_envs}, dofs_per_env={self.dofs_per_env})")
        print(
            f"  å‰5ä¸ªç´¢å¼•: {self.robot_dof_start_indices[:5] if len(self.robot_dof_start_indices) >= 5 else self.robot_dof_start_indices}")

        # åœ¨g1_kitchen_navigation.pyçš„_init_buffersæ–¹æ³•ä¸­ï¼Œç¡®ä¿è¿™æ®µä»£ç è¢«æ‰§è¡Œ
        all_robot_dof_indices = []
        for i in range(self.num_envs):
            start = self.robot_dof_start_indices[i]
            all_robot_dof_indices.extend(range(start, start + self.num_dof))
        self.all_robot_dof_indices = torch.tensor(all_robot_dof_indices, dtype=torch.long, device=self.device)
        print(f"  å·²åˆå§‹åŒ– all_robot_dof_indices (å½¢çŠ¶: {self.all_robot_dof_indices.shape})")

        # --- 6. Reshape global tensors for easier access ---
        try:
            self.rigid_body_states_view = self.rigid_body_states.view(self.num_envs, self.bodies_per_env, 13)
            print(f"  Reshaped rigid_body_states to: {self.rigid_body_states_view.shape}")
        except RuntimeError as e:
            print(f"âš ï¸ WARNING: Failed to reshape rigid_body_states: {e}. Feet tracking might fail.")
            self.rigid_body_states_view = None

        try:
            self.contact_forces = self.contact_forces_raw.view(self.num_envs, self.bodies_per_env, 3)
            print(f"  Reshaped contact_forces to: {self.contact_forces.shape}")
        except RuntimeError as e:
            print(f"âš ï¸ WARNING: Failed to reshape contact_forces_raw: {e}. Using raw tensor.")
            self.contact_forces = self.contact_forces_raw # Use raw

        # --- 7. åˆå§‹åŒ–å…¶ä»–ç¼“å†²åŒº (ä¸ LeggedRobot ç±»ä¼¼, ä½¿ç”¨æœºå™¨äººç»´åº¦) ---
        self.rpy = torch.zeros_like(self.base_pos)
        self.common_step_counter = 0
        self.extras = {}
        self.noise_scale_vec = self._get_noise_scale_vec(self.cfg) # Noise vec for robot obs
        self.gravity_vec = to_torch(get_axis_params(-1., self.up_axis_idx), device=self.device).repeat((self.num_envs, 1))
        self.forward_vec = to_torch([1., 0., 0.], device=self.device).repeat((self.num_envs, 1))

        # Action related (size num_actions = robot's num_dof)
        self.actions = torch.zeros(self.num_envs, self.num_actions, dtype=torch.float, device=self.device, requires_grad=False)
        self.last_actions = torch.zeros_like(self.actions)
        self.p_gains = torch.zeros(self.num_actions, dtype=torch.float, device=self.device, requires_grad=False)
        self.d_gains = torch.zeros_like(self.p_gains)
        self.torque_limits = torch.zeros_like(self.p_gains)

        # Global torque buffer (size total_sim_dofs)
        self.torques = torch.zeros(self.sim_total_dofs, dtype=torch.float, device=self.device, requires_grad=False)
        print(f"  Torques buffer shape (KitchenNav): {self.torques.shape}")

        # Last velocities (robot specific shapes)
        self.last_dof_vel = torch.zeros_like(self.dof_vel)
        self.last_root_vel = torch.zeros_like(self.robot_root_states[:, 7:13])

        # Commands
        self.commands = torch.zeros(self.num_envs, self.cfg.commands.num_commands, dtype=torch.float, device=self.device, requires_grad=False)
        self.commands_scale = torch.tensor([self.obs_scales.lin_vel, self.obs_scales.lin_vel, self.obs_scales.ang_vel], device=self.device, requires_grad=False,)

        # Feet contact buffers
        if self.feet_indices.numel() > 0:
            self.feet_air_time = torch.zeros(self.num_envs, self.feet_indices.shape[0], dtype=torch.float, device=self.device, requires_grad=False)
            self.last_contacts = torch.zeros(self.num_envs, len(self.feet_indices), dtype=torch.bool, device=self.device, requires_grad=False)
        else: self.feet_air_time = None; self.last_contacts = None

        # Calculated velocities (using robot states)
        self.base_lin_vel = quat_rotate_inverse(self.base_quat, self.robot_root_states[:, 7:10])
        self.base_ang_vel = quat_rotate_inverse(self.base_quat, self.robot_root_states[:, 10:13])
        self.projected_gravity = quat_rotate_inverse(self.base_quat, self.gravity_vec)

        # --- 8. è®¾ç½®é»˜è®¤ DoF ä½ç½®å’Œ PD å¢ç›Š (é’ˆå¯¹æœºå™¨äºº DoF) ---
        self.default_dof_pos = torch.zeros(self.num_dof, dtype=torch.float, device=self.device, requires_grad=False)
        # Need robot asset's DoF props
        first_robot_handle = self.actor_handles[0]  # Use first robot actor handle
        dof_props_asset = self.gym.get_actor_dof_properties(self.envs[0], first_robot_handle)  # Get props from actor

        for i in range(self.num_dof):
            name = self.dof_names[i]
            angle = self.cfg.init_state.default_joint_angles.get(name, 0.0)
            self.default_dof_pos[i] = angle

            # å®‰å…¨åœ°è½¬æ¢ç±»å‹
            effort_value = dof_props_asset["effort"][i]
            self.torque_limits[i] = float(effort_value.item()) if hasattr(effort_value, 'item') else float(effort_value)

            found = False
            for gain_key, stiffness_val in self.cfg.control.stiffness.items():
                if gain_key in name:
                    self.p_gains[i] = stiffness_val
                    self.d_gains[i] = self.cfg.control.damping.get(gain_key, 0.0)
                    found = True;
                    break
            if not found: self.p_gains[i] = 0.; self.d_gains[i] = 0.
        self.default_dof_pos = self.default_dof_pos.unsqueeze(0)

        # --- 9. åˆå§‹åŒ–è¶³éƒ¨è¿½è¸ª (ä½¿ç”¨ view) ---
        self._init_foot() # Uses self.rigid_body_states_view and self.feet_indices

        print("--- _init_buffers (G1KitchenNavigation) Done ---")


    def _init_foot(self):
        """ é‡å†™ä»¥ä½¿ç”¨æ­£ç¡®çš„è§†å›¾å’Œç´¢å¼• """
        if self.feet_indices is None or self.feet_indices.numel() == 0:
            self.feet_num = 0; self.feet_state = None; self.feet_pos = None; self.feet_vel = None; return

        self.feet_num = len(self.feet_indices)

        if self.rigid_body_states_view is not None:
            # feet_indices are *local* robot body indices
            # rigid_body_states_view is [num_envs, bodies_per_env, 13]
            # We need the view for the *robot* bodies within each env slice
            # Assuming robot bodies are the first self.num_bodies in each env slice
            robot_rigid_body_view = self.rigid_body_states_view[:, :self.num_bodies, :]
            if torch.any(self.feet_indices >= robot_rigid_body_view.shape[1]):
                 print(f"âŒ ERROR _init_foot: feet_indices ({self.feet_indices.max().item()}) out of bounds for robot body view dim ({robot_rigid_body_view.shape[1]})")
                 self.feet_num = 0; self.feet_state=None; self.feet_pos=None; self.feet_vel=None; return

            self.feet_state = robot_rigid_body_view[:, self.feet_indices, :]
            self.feet_pos = self.feet_state[:, :, :3]
            self.feet_vel = self.feet_state[:, :, 7:10]
            print("  âœ… Initialized foot state views.")
        else:
            print("âš ï¸ _init_foot: rigid_body_states_view not available. Foot state tracking disabled.")
            self.feet_state = None; self.feet_pos = None; self.feet_vel = None


    def update_feet_state(self):
        """ æ›´æ–°è¶³éƒ¨çŠ¶æ€ (Kitchen Nav version) """
        if self.feet_num > 0 and self.rigid_body_states_view is not None:
            # Refresh global tensor
            self.gym.refresh_rigid_body_state_tensor(self.sim)
            # Re-slice from the robot's part of the view
            robot_rigid_body_view = self.rigid_body_states_view[:, :self.num_bodies, :]
            if torch.any(self.feet_indices >= robot_rigid_body_view.shape[1]): return # Already warned
            self.feet_state = robot_rigid_body_view[:, self.feet_indices, :]
            self.feet_pos = self.feet_state[:, :, :3]
            self.feet_vel = self.feet_state[:, :, 7:10]


    def _compute_torques(self, actions):
        """ è®¡ç®—æ‰­çŸ©ï¼Œå¡«å……åˆ°å…¨å±€æ‰­çŸ©å¼ é‡ (Kitchen Nav version) """
        # --- 1. è®¡ç®—æœºå™¨äººçš„æ‰­çŸ© ---
        if actions.shape[1] != self.num_actions: raise ValueError("Action shape mismatch")
        actions_scaled = actions * self.cfg.control.action_scale
        control_type = self.cfg.control.control_type

        # Use robot's DoF states from manually updated buffers
        if not self.manual_dof_update: print("âš ï¸ _compute_torques expects manual_dof_update=True")
        if self.dof_pos.shape[1] != self.num_actions: raise ValueError("dof_pos shape mismatch")
        if self.dof_vel.shape[1] != self.num_actions: raise ValueError("dof_vel shape mismatch")

        if control_type == "P":
            robot_torques = self.p_gains * (actions_scaled + self.default_dof_pos - self.dof_pos) - self.d_gains * self.dof_vel
        elif control_type == "V":
            if self.last_dof_vel.shape != self.dof_vel.shape: self.last_dof_vel = torch.zeros_like(self.dof_vel)
            dt = self.dt
            if dt <= 0: dt = 1e-5
            robot_torques = self.p_gains * (actions_scaled - self.dof_vel) - self.d_gains * ((self.dof_vel - self.last_dof_vel) / dt)
        elif control_type == "T": robot_torques = actions_scaled
        else: raise NameError(f"æœªçŸ¥æ§åˆ¶å™¨ç±»å‹: {control_type}")

        robot_torques = torch.clip(robot_torques, -self.torque_limits, self.torque_limits) # Shape [num_envs, 43]

        # --- 2. å°†æœºå™¨äººæ‰­çŸ©å¡«å……åˆ°å…¨å±€æ‰­çŸ©å¼ é‡ ---
        self.torques.zero_() # Zero out global tensor
        flat_robot_torques = robot_torques.view(-1) # Shape [num_envs * 43]
        if flat_robot_torques.shape == self.all_robot_dof_indices.shape:
             self.torques.index_copy_(0, self.all_robot_dof_indices, flat_robot_torques)
        else: print(f"âŒ ERROR _compute_torques: Mismatch flat torques vs indices")

        return self.torques # Return the full torque tensor [sim_total_dofs]


    # --- å¯¼èˆªå’Œç‰¹å®šé˜¶æ®µé€»è¾‘ ---
    def _initialize_kitchen_waypoints(self):
        """ åˆå§‹åŒ–å¨æˆ¿å¯¼èˆªç‚¹ """
        print("--- _initialize_kitchen_waypoints (G1KitchenNavigation) ---")
        # ä»é…ç½®æˆ–é»˜è®¤å€¼è·å–
        # ç¡®ä¿åæ ‡ç›¸å¯¹äº Kitchen åœºæ™¯åŸç‚¹æˆ–ä¸–ç•ŒåŸç‚¹ä¸€è‡´
        # !!! è¿™äº›åæ ‡éœ€è¦æ ¹æ®ä½ çš„å®é™…åœºæ™¯ç²¾ç¡®è®¾ç½® !!!
        default_waypoints = {
            "entrance": [0.0, -1.0, 0.0],       # Env origin entrance area
            "fridge_front": [1.5, 1.0, 0.0],    # In front of fridge
            "counter_middle": [0.0, 2.5, 0.0],   # Middle of counter
            "table_center": [-1.5, 1.0, 0.0],   # Center of table area
        }
        wp_dict_cfg = getattr(self.cfg, 'waypoints', default_waypoints)
        self.waypoints = {name: torch.tensor(pos, device=self.device) for name, pos in wp_dict_cfg.items()}

        self.waypoint_names = list(self.waypoints.keys())
        if not self.waypoint_names: print("âš ï¸ æœªå®šä¹‰ä»»ä½•å¯¼èˆªç‚¹ã€‚"); return
        self.waypoint_positions = torch.stack(list(self.waypoints.values()))
        print(f"  Defined {len(self.waypoint_names)} waypoints: {self.waypoint_names}")

        sub_stage = self.curriculum_sub_stage # Use instance attribute
        # Example sub-stage logic (adjust as needed)
        if sub_stage <= 2:   self.active_waypoints = ["entrance", "fridge_front", "counter_middle"]
        else:                self.active_waypoints = self.waypoint_names
        try:
            self.active_waypoint_indices = [self.waypoint_names.index(name) for name in self.active_waypoints if name in self.waypoint_names] # Filter only existing names
            print(f"  Sub-stage {sub_stage}: Active waypoints = {self.active_waypoints} (Indices: {self.active_waypoint_indices})")
        except ValueError as e:
             print(f"âŒ Error finding waypoint index: {e}")
             self.active_waypoint_indices = list(range(len(self.waypoint_names))) # Fallback


    def _sample_navigation_targets(self, env_ids=None):
        """ ä¸ºæŒ‡å®šç¯å¢ƒé‡‡æ ·æ–°çš„ã€ä¸åŒäºä¸Šä¸€ä¸ªç›®æ ‡çš„å¯¼èˆªç‚¹ """
        if env_ids is None: env_ids = torch.arange(self.num_envs, device=self.device)
        if len(env_ids) == 0 or not self.active_waypoint_indices: return

        num_active = len(self.active_waypoint_indices)
        if num_active <= 1:
            new_indices_in_active_list = torch.zeros_like(env_ids)
        else:
            new_indices_in_active_list = torch.randint(0, num_active, (len(env_ids),), device=self.device)
            current_target_full_idx = self.current_waypoint_idx[env_ids]
            active_indices_tensor = torch.tensor(self.active_waypoint_indices, device=self.device)

            for i, env_id in enumerate(env_ids):
                 current_wp_idx = current_target_full_idx[i].item()
                 current_active_idx = -1
                 if current_wp_idx in self.active_waypoint_indices:
                      current_active_idx = self.active_waypoint_indices.index(current_wp_idx)

                 num_tries = 0
                 while new_indices_in_active_list[i].item() == current_active_idx and num_tries < 5:
                       new_indices_in_active_list[i] = torch.randint(0, num_active, (1,), device=self.device)[0]
                       num_tries += 1

        new_waypoint_indices = active_indices_tensor[new_indices_in_active_list]
        self.last_waypoint_idx[env_ids] = self.current_waypoint_idx[env_ids].clone()
        self.current_waypoint_idx[env_ids] = new_waypoint_indices
        self.target_positions[env_ids] = self.waypoint_positions[new_waypoint_indices]
        self.reached_waypoint[env_ids] = False
        self.collision_detected[env_ids] = False


    def _get_collision_body_indices(self):
        """ è·å–ç”¨äºç¢°æ’æ£€æµ‹çš„ Body Indices """
        # Robot non-foot bodies (local indices 0 to num_bodies-1)
        if self.feet_indices is not None:
             self.robot_non_foot_indices = [j for j in range(self.num_bodies) if j not in self.feet_indices.cpu().tolist()]
             print(f"  Robot non-foot indices (local): {self.robot_non_foot_indices}")
        else:
             self.robot_non_foot_indices = list(range(self.num_bodies)) # Assume all bodies if feet unknown
             print("  âš ï¸ Feet indices not found, using all robot bodies for collision check.")


    def _check_collision(self):
        """ æ£€æŸ¥æœºå™¨äººéè¶³éƒ¨ä¸ç¯å¢ƒçš„ç¢°æ’ """
        if self.contact_forces is None or not self.robot_non_foot_indices:
             return torch.zeros(self.num_envs, dtype=torch.bool, device=self.device)

        # Assuming self.contact_forces is shape [num_envs, bodies_per_env, 3]
        # Robot bodies are the first self.num_bodies slice
        robot_contact_forces = self.contact_forces[:, :self.num_bodies, :]
        non_foot_forces_norm = torch.norm(robot_contact_forces[:, self.robot_non_foot_indices, :], dim=2)

        collision_threshold = getattr(self.cfg.rewards, 'collision_force_threshold', 5.0)
        collision = torch.any(non_foot_forces_norm > collision_threshold, dim=1)

        # Update latched collision flag for the current target pursuit
        newly_collided = collision & (~self.collision_detected) # Detect only new collisions
        if newly_collided.any():
             self.collision_detected[newly_collided] = True # Latch collision
             self.consecutive_successes[newly_collided] = 0 # Reset success count on collision
             # print(f"Collision detected in envs: {torch.nonzero(newly_collided).squeeze(-1).cpu().tolist()}")

        return collision # Return per-step collision status


    def _check_waypoint_reached(self, distance_threshold=None):
        """ æ£€æŸ¥æ˜¯å¦åˆ°è¾¾å½“å‰å¯¼èˆªç‚¹ """
        if distance_threshold is None:
             distance_threshold = getattr(self.cfg.rewards, 'waypoint_reach_threshold', 0.5)
        if self.target_positions is None: return torch.zeros(self.num_envs, dtype=torch.bool, device=self.device)

        robot_pos_xy = self.robot_root_states[:, :2]
        target_pos_xy = self.target_positions[:, :2]
        distances = torch.norm(robot_pos_xy - target_pos_xy, dim=1)
        self.dist_to_target = distances
        reached = distances < distance_threshold
        # Don't latch self.reached_waypoint here, do it in post_physics_step based on resample condition
        return reached # Return per-step reach status

    def compute_observations(self):
        """ Computes G1 specific base observations (e.g., 140 dims including phase).
            Child classes will call this via super() and append their specific observations.
        """
        # --- 1. è®¡ç®—é€šç”¨ç»„ä»¶ ---
        # Phase (ensure it's calculated in _post_physics_step_callback)
        if not hasattr(self, 'phase'): self.phase = torch.zeros(self.num_envs, device=self.device)
        sin_phase = torch.sin(2 * torch.pi * self.phase).unsqueeze(1)
        cos_phase = torch.cos(2 * torch.pi * self.phase).unsqueeze(1)

        # Scaled DoF states (ensure dof_pos/vel are correct shape [num_envs, num_dof])
        if self.dof_pos.shape != (self.num_envs, self.num_dof) or self.dof_vel.shape != (self.num_envs, self.num_dof):
            print(f"âŒ ERROR compute_observations: DOF state shape mismatch!")
            # Fallback to zeros with correct shape for buffer concatenation
            dof_pos_scaled = torch.zeros((self.num_envs, self.num_dof), device=self.device)
            dof_vel_scaled = torch.zeros((self.num_envs, self.num_dof), device=self.device)
        else:
            dof_pos_scaled = (self.dof_pos - self.default_dof_pos) * self.obs_scales.dof_pos
            dof_vel_scaled = self.dof_vel * self.obs_scales.dof_vel

        # Scaled base velocities and commands
        base_ang_vel_scaled = self.base_ang_vel * self.obs_scales.ang_vel
        commands_scaled = self.commands[:, :3] * self.commands_scale  # Assuming commands_scale is set

        # Previous actions (ensure shape is correct)
        actions_to_include = self.actions
        if actions_to_include.shape != (self.num_envs, self.num_actions):
            print(
                f"âš ï¸ WARNING compute_observations: self.actions shape {actions_to_include.shape} unexpected. Using zeros.")
            actions_to_include = torch.zeros((self.num_envs, self.num_actions), device=self.device)

        # --- 2. ç»„è£… G1 åŸºç¡€è§‚æµ‹åˆ—è¡¨ (140 ç»´) ---
        # é¡ºåºå¿…é¡»ä¸ _get_noise_scale_vec ä¸­çš„å‡è®¾ä¸€è‡´
        # 3(ang_vel) + 3(gravity) + 3(commands) + 43(dof_pos) + 43(dof_vel) + 43(actions) + 2(phase) = 140
        obs_list = [
            base_ang_vel_scaled,  # 3
            self.projected_gravity,  # 3
            commands_scaled,  # 3
            dof_pos_scaled,  # 43 (num_actions)
            dof_vel_scaled,  # 43 (num_actions)
            actions_to_include,  # 43 (num_actions) - previous actions
            sin_phase,  # 1
            cos_phase  # 1
        ]

        # --- 3. æ‹¼æ¥æˆæœ€ç»ˆçš„ obs_buf ---
        try:
            self.obs_buf = torch.cat(obs_list, dim=-1)
            # éªŒè¯ç»´åº¦
            if self.obs_buf.shape[1] != self.num_observations:
                print(
                    f"âŒ ERROR: G1CurriculumBase computed obs dim ({self.obs_buf.shape[1]}) != configured num_observations ({self.num_observations}). Check obs_list!")
                # Attempt to fix shape for safety, though it indicates a logic error
                if self.obs_buf.shape[1] > self.num_observations:
                    self.obs_buf = self.obs_buf[:, :self.num_observations]
                else:
                    padding = torch.zeros((self.num_envs, self.num_observations - self.obs_buf.shape[1]),
                                          device=self.device)
                    self.obs_buf = torch.cat([self.obs_buf, padding], dim=-1)

        except Exception as e:
            print("âŒ G1CurriculumBase ERROR concatenating observation buffer:")
            for i, item in enumerate(obs_list): print(
                f"  Item {i}: shape={item.shape if hasattr(item, 'shape') else 'N/A'}")
            print(f"  Error: {e}")
            # Fallback to zeros
            self.obs_buf = torch.zeros(self.num_envs, self.num_observations, device=self.device, dtype=torch.float)

        # --- 4. ç»„è£…ç‰¹æƒè§‚æµ‹ ---
        if self.privileged_obs_buf is not None:
            # ç‰¹æƒè§‚æµ‹ = åŸºç¡€çº¿é€Ÿåº¦(3) + æ™®é€šè§‚æµ‹(140) = 143 (è¿™æ˜¯åŸºç¡€ç‰¹æƒè§‚æµ‹)
            priv_obs_list = [
                self.base_lin_vel * self.obs_scales.lin_vel,  # 3
                self.obs_buf  # 140 (G1 base obs)
            ]
            try:
                self.privileged_obs_buf = torch.cat(priv_obs_list, dim=-1)
                # éªŒè¯ç»´åº¦
                if self.privileged_obs_buf.shape[1] != self.num_privileged_obs:
                    print(
                        f"âŒ ERROR: G1CurriculumBase computed priv_obs dim ({self.privileged_obs_buf.shape[1]}) != configured num_privileged_obs ({self.num_privileged_obs}). Check priv_obs_list!")
                    # Attempt to fix shape
                    if self.privileged_obs_buf.shape[1] > self.num_privileged_obs:
                        self.privileged_obs_buf = self.privileged_obs_buf[:, :self.num_privileged_obs]
                    else:
                        padding = torch.zeros(
                            (self.num_envs, self.num_privileged_obs - self.privileged_obs_buf.shape[1]),
                            device=self.device)
                        self.privileged_obs_buf = torch.cat([self.privileged_obs_buf, padding], dim=-1)

            except Exception as e:
                print("âŒ G1CurriculumBase ERROR concatenating privileged observation buffer:")
                for i, item in enumerate(priv_obs_list): print(
                    f"  Item {i}: shape={item.shape if hasattr(item, 'shape') else 'N/A'}")
                print(f"  Error: {e}")
                # Fallback to zeros
                self.privileged_obs_buf = torch.zeros(self.num_envs, self.num_privileged_obs, device=self.device,
                                                      dtype=torch.float)

        # --- 5. æ·»åŠ å™ªå£° (åœ¨è§‚æµ‹è®¡ç®—å®Œæˆå) ---
        if self.add_noise:
            # Check noise vector compatibility
            if self.noise_scale_vec is not None and self.noise_scale_vec.shape[0] == self.num_observations:
                self.obs_buf += (2 * torch.rand_like(self.obs_buf) - 1) * self.noise_scale_vec
            else:
                # Warning already printed in _get_noise_scale_vec if size mismatch
                pass



    # --- Stage 2 Specific Reward Functions ---
    def _reward_waypoint_distance(self):
        if self.dist_to_target is None: return torch.zeros(self.num_envs, device=self.device)
        k = getattr(self.cfg.rewards, 'distance_reward_k', 0.5)
        return torch.exp(-k * self.dist_to_target)

    def _reward_waypoint_reached(self):
        # Reward only on the step the waypoint is first reached before resampling
        return self.reached_waypoint.float() # Use the per-step flag

    def _reward_kitchen_collision(self):
        # Penalize based on the per-step collision check
        collision_this_step = self._check_collision() # This also updates the latched flag
        return collision_this_step.float() # Returns 1.0 if collision this step, 0.0 otherwise

    def _reward_target_facing(self):
        if self.target_positions is None: return torch.zeros(self.num_envs, device=self.device)
        robot_pos_xy = self.robot_root_states[:, :2]
        target_pos_xy = self.target_positions[:, :2]
        target_dir_world = target_pos_xy - robot_pos_xy
        target_dir_norm = torch.norm(target_dir_world, dim=1, keepdim=True)
        target_dir_world = target_dir_world / (target_dir_norm + 1e-8)

        robot_fwd_world = quat_apply(self.robot_root_states[:, 3:7], self.forward_vec)[:, :2]
        robot_fwd_norm = torch.norm(robot_fwd_world, dim=1, keepdim=True)
        robot_fwd_world = robot_fwd_world / (robot_fwd_norm + 1e-8)

        cos_similarity = torch.sum(robot_fwd_world * target_dir_world, dim=1)
        # Reward based on cosine similarity (e.g., scale to [0, 1])
        facing_reward = torch.clamp(cos_similarity, min=0.0) # Only reward positive alignment
        # facing_reward = (cos_similarity + 1.0) / 2.0 # Scale -1..1 to 0..1
        return facing_reward

    # compute_reward: Inherited from G1CurriculumBase/LeggedRobot,
    # it will call all _reward_* functions found based on reward_scales.

    # --- Stage 2 Success Criteria ---
    def compute_success_criteria(self):
        """ Stage 2 Success: Reached N waypoints consecutively without collision. """
        success_threshold = getattr(self.cfg.curriculum, 'stage2_success_waypoint_count', 3)
        # Check the counter *before* potentially resetting it in post_physics_step
        success_flags = self.consecutive_successes >= success_threshold
        return success_flags


    def post_physics_step(self):
        """ Stage 2 Post Physics Step """
        # --- 1. è°ƒç”¨çˆ¶ç±» (G1CurriculumBase) -> LeggedRobot ---

        if hasattr(self, '_manual_dof_update'):
            self._manual_dof_update()
        else:
            print("è­¦å‘Š: _manual_dof_update æ–¹æ³•ä¸å­˜åœ¨")
        # Handles refreshing tensors, base state updates, phase calculation, command resampling, heading command
        super().post_physics_step() # Calls G1CurriculumBase._post_physics_step_callback internally

        # --- 2. Stage 2 Specific Logic: Collision and Waypoint Reached ---
        self._check_collision() # Updates self.collision_detected, resets counter if collision
        reached = self._check_waypoint_reached() # Per-step check

        # --- 3. Re-sample Target if Reached Successfully ---
        resample_condition = reached & (~self.collision_detected) # Must reach *without* collision currently latched
        env_ids_to_resample = torch.nonzero(resample_condition).squeeze(-1)
        if len(env_ids_to_resample) > 0:
             # Increment consecutive success counter *before* resampling
             self.consecutive_successes[env_ids_to_resample] += 1
             self._sample_navigation_targets(env_ids_to_resample) # Samples new target, resets reached_waypoint flag
             # Don't set self.reached_waypoint = True here, use the per-step 'reached' for reward


        # --- 4. Compute Observations, Rewards, Termination ---
        # These are called by the parent's post_physics_step *after* the callback.
        # We might need to recompute observations if target changed? Let's test.
        # Recompute observations here AFTER potential target change
        self.compute_observations()

        # --- 5. Set extras for Runner ---
        success_flags = self.compute_success_criteria()
        self.extras["success_flags"] = success_flags.clone()
        # Reset counter only AFTER checking success for this step
        if success_flags.any():
             self.consecutive_successes[success_flags] = 0

        # --- 6. Handle Resets (Parent's post_physics_step calls reset_idx) ---
        # Our overridden reset_idx will handle navigation state resets.

    def reset_idx(self, env_ids):
         """ é‡å†™ reset_idx ä»¥é‡ç½®å¯¼èˆªçŠ¶æ€ """
         if len(env_ids) == 0: return
         # print(f"Resetting envs (G1KitchenNav): {env_ids.cpu().tolist()}")
         # è°ƒç”¨çˆ¶ç±» reset (é‡ç½®æœºå™¨äººçŠ¶æ€ã€å‘½ä»¤ã€åŸºç¡€ç¼“å†²åŒºç­‰)
         super().reset_idx(env_ids) # Calls LeggedRobot.reset_idx -> BaseTask.reset_idx placeholder -> G1BasicLocomotion.reset_idx
         # G1BasicLocomotion reset_idx resets streak counter, we need to reset nav state here

         # é‡ç½®æœ¬é˜¶æ®µç‰¹å®šçš„çŠ¶æ€
         if self.consecutive_successes is not None: self.consecutive_successes[env_ids] = 0
         if self.collision_detected is not None: self.collision_detected[env_ids] = False
         if self.reached_waypoint is not None: self.reached_waypoint[env_ids] = False
         self._sample_navigation_targets(env_ids) # Sample initial targets for reset envs
         # print(f"  G1KitchenNavigation: Reset navigation state for {len(env_ids)} environments.")